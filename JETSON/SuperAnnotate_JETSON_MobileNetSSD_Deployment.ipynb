{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\"><td><a target=\"_blank\" href=\"https://colab.research.google.com/github/superannotateai/model-deployment-tutorials/blob/main/JETSON/SuperAnnotate_JETSON_MobileNetSSD_Deployment.ipynb\"><img src=\"https://user-images.githubusercontent.com/25985824/104791629-6e618700-5769-11eb-857f-d176b37d2496.png\" height=\"32\" width=\"32\"> Try in Google Colab</a></td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klDMMxDwzQ_j"
   },
   "source": [
    "# 0. Preparation Steps\n",
    "Before starting the pipeline you need to download tgz archives of TensorRT and CUDNN and place them in your google drive. (This notebook is tested with TensorRT 7.2.3.4 and CUDNN-11.2 versions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P14SDT47-Kcf"
   },
   "source": [
    "# 1. Install Prerequisites \n",
    "(Please click on **RESTART RUNTIME** button when it appears in the output of this code block)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IeakIbyX0vJu"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SoiYFLBC-j5u"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/brokenerk/TRT-SSD-MobileNetV2.git\n",
    "!cp /content/drive/MyDrive/TensorRT-7.2.3.4.Ubuntu-18.04.x86_64-gnu.cuda-11.0.cudnn8.1.tar.gz /content/\n",
    "!cp /content/drive/MyDrive/cudnn-11.2-linux-x64-v8.1.1.33.tgz /content/\n",
    "\n",
    "!tar -xzvf cudnn-11.2-linux-x64-v8.1.1.33.tgz\n",
    "\n",
    "!sudo cp cuda/include/cudnn*.h /usr/local/cuda/include \n",
    "!sudo cp -P cuda/lib64/libcudnn* /usr/local/cuda/lib64 \n",
    "!sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*\n",
    "\n",
    "!tar xzvf TensorRT-7.2.3.4.Ubuntu-18.04.x86_64-gnu.cuda-11.0.cudnn8.1.tar.gz\n",
    "os.environ['LD_LIBRARY_PATH'] += ':/content/TensorRT-7.2.3.4/lib/'\n",
    "\n",
    "%cd /content/TensorRT-7.2.3.4/python/\n",
    "!sudo pip3 install tensorrt-7.2.3.4-cp37-none-linux_x86_64.whl\n",
    "\n",
    "%cd /content/TensorRT-7.2.3.4/uff/\n",
    "!sudo pip3 install uff-0.6.9-py2.py3-none-any.whl\n",
    "\n",
    "%cd /content/TensorRT-7.2.3.4/graphsurgeon/\n",
    "!sudo pip3 install graphsurgeon-0.4.5-py2.py3-none-any.whl\n",
    "%cd /content/TensorRT-7.2.3.4/onnx_graphsurgeon\n",
    "!sudo pip3 install onnx_graphsurgeon-0.2.6-py2.py3-none-any.whl\n",
    "\n",
    "!pip install superannotate\n",
    "!pip install google-resumable-media==0.5.0\n",
    "\n",
    "!pip install numpy==1.17.5\n",
    "!pip install tf_slim\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip libjpeg8-dev liblapack-dev libblas-dev gfortran\n",
    "!sudo apt-get install python3-pip\n",
    "!pip3 install -U pip testresources setuptools==49.6.0\n",
    "!pip3 install future==0.18.2 mock==3.0.5 h5py==2.10.0 keras_preprocessing==1.1.1 keras_applications==1.0.8 gast==0.2.2 futures protobuf pybind11\n",
    "!pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v43 'tensorflow<2'\n",
    "!pip3 install pycuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxLgFeFi-hqZ"
   },
   "source": [
    "# 2. Setup your SuperAnnotate token, project names of trianing images and desired output model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eM8xn82K-uUm"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "\n",
    "TOKEN = \"For Pro Users, the Token-ID can be generated in the teams section\"\n",
    "PROJECT_NAMES = [\"Mask - batch 1\", \"Mask - batch 2\"]\n",
    "OUTPUT_MODEL = \"sa-tutorial\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mU4uDCW-Wp7"
   },
   "source": [
    "# 3. Download and preprocess the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FITOUc3E9JXU"
   },
   "outputs": [],
   "source": [
    "import superannotate as sa\n",
    "import json\n",
    "import os \n",
    "from shutil import copy, make_archive, rmtree\n",
    "import re\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "\n",
    "os.environ['CUDA_INSTALL_DIR']= \"/usr/local/cuda/\"\n",
    "os.environ['CUDNN_INSTALL_DIR']= \"/usr/local/cuda/\"\n",
    "os.environ['LD_LIBRARY_PATH']+= \":/usr/lib64-nvidia/:/content/TensorRT-7.2.3.4/include/:/content/TensorRT-7.2.3.4/targets/x86_64-linux-gnu/lib/:/content/TensorRT-7.2.3.4/targets/x86_64-linux-gnu/bin/\"\n",
    "os.environ['PATH']+= \":/content/TensorRT-7.2.3.4/targets/x86_64-linux-gnu/lib:/content/TensorRT-7.2.3.4/targets/x86_64-linux-gnu/bin/\"\n",
    "!sudo rm /content/TensorRT-7.2.3.4/targets/x86_64-linux-gnu/lib/libnvinfer.so.7\n",
    "!sudo ln -s /content/TensorRT-7.2.3.4/targets/x86_64-linux-gnu/lib/libnvinfer.so.7.2.3 /content/TensorRT-7.2.3.4/targets/x86_64-linux-gnu/lib/libnvinfer.so.7\n",
    "!sudo cp -r /content/TensorRT-7.2.3.4/targets/x86_64-linux-gnu/lib/*.* /usr/lib/ \n",
    "!sudo cp -r /content/TensorRT-7.2.3.4/targets/x86_64-linux-gnu/bin/*.* /usr/bin/ \n",
    "\n",
    "proj_folder = dict(zip(PROJECT_NAMES, [\"proj_\" + str(i) for i in range(len(PROJECT_NAMES))]))\n",
    "token_json = {\"token\": TOKEN}\n",
    "with open('sa_config.json', 'w') as f:\n",
    "  json.dump(token_json, f)\n",
    "\n",
    "sa.init('sa_config.json')\n",
    "\n",
    "for project_name, folder_name in proj_folder.items():\n",
    "  if not os.path.exists('./training_data/' + folder_name):\n",
    "    os.makedirs('training_data/' + folder_name)\n",
    "  completed_images = sa.search_images(project_name, annotation_status=\"Completed\")\n",
    "  for completed_image in completed_images:\n",
    "    sa.download_image(project_name, completed_image, local_dir_path='./training_data/' + folder_name)\n",
    "  export = sa.prepare_export(project_name, annotation_statuses=[\"Completed\"])\n",
    "  sa.download_export(project_name, export, './training_data/' + folder_name)\n",
    "\n",
    "%cd /content\n",
    "!git clone --quiet https://github.com/tensorflow/models.git\n",
    "%cd /content/models/\n",
    "!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n",
    "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
    "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
    "!pip install -q pycocotools\n",
    "%cd /content/models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
    "\n",
    "%cd /content/models/research/\n",
    "from object_detection.utils import dataset_util, label_map_util\n",
    "data_base = Path(\"/content/training_data\")\n",
    "class_names = set()\n",
    "column_names = [\"filename\", \"width\", \"height\", \"class\", \"xmin\", \"ymin\", \"xmax\", \"ymax\"]\n",
    "for project_dir in data_base.glob(\"*\"):\n",
    "  with open(project_dir / \"classes\" / \"classes.json\") as f:\n",
    "    proj_class_data = json.load(f)\n",
    "  for class_entry in proj_class_data:\n",
    "    class_names.add(class_entry[\"name\"])\n",
    "class_names = sorted(list(class_names))\n",
    "pbtxt_content = \"\"\n",
    "for i, class_name in enumerate(class_names):\n",
    "  pbtxt_content = (pbtxt_content + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name))\n",
    "pbtxt_content = pbtxt_content.strip()\n",
    "with (data_base / \"label_map.pbtxt\").open(mode=\"w\") as f:\n",
    "  f.write(pbtxt_content)\n",
    "\n",
    "tf_record_dir = data_base / \"annotations\"\n",
    "if not tf_record_dir.exists():\n",
    "  tf_record_dir.mkdir()\n",
    "\n",
    "writers = [tf.python_io.TFRecordWriter(str(tf_record_dir / \"train.record\")), tf.python_io.TFRecordWriter(str(tf_record_dir / \"test.record\"))]\n",
    "label_map = label_map_util.load_labelmap(str(data_base / \"label_map.pbtxt\"))\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=90, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "label_map = {}\n",
    "for k, v in category_index.items():\n",
    "    label_map[v.get(\"name\")] = v.get(\"id\")\n",
    "    \n",
    "for project_dir in list(data_base.glob(\"*\")):\n",
    "  annot_paths = list(project_dir.glob(\"*___objects.json\"))\n",
    "  for annot_path in annot_paths:\n",
    "    with open(annot_path) as f:\n",
    "      annot_data = json.load(f)\n",
    "    file_name = annot_path.name[:-15]\n",
    "    with tf.gfile.GFile(str(project_dir / file_name), \"rb\") as fid:\n",
    "      encoded_jpg = fid.read()\n",
    "    width = annot_data[\"metadata\"][\"width\"]\n",
    "    height = annot_data[\"metadata\"][\"height\"]\n",
    "    image_format = Path(file_name).suffix[1:].encode(\"utf8\")\n",
    "    file_name = file_name.encode(\"utf8\")\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "    for inst_data in annot_data[\"instances\"]:\n",
    "      points = inst_data[\"points\"]\n",
    "      xmin, xmax = min(points[\"x1\"], points[\"x2\"]), max(points[\"x1\"], points[\"x2\"])\n",
    "      ymin, ymax = min(points[\"y1\"], points[\"y2\"]), max(points[\"y1\"], points[\"y2\"])\n",
    "      xmins.append(xmin / width)\n",
    "      xmaxs.append(xmax / width)\n",
    "      ymins.append(ymin / height)\n",
    "      ymaxs.append(ymax / height)\n",
    "      classes_text.append(inst_data[\"className\"].encode(\"utf8\"))\n",
    "      class_index = label_map.get(inst_data[\"className\"])\n",
    "      classes.append(class_index)\n",
    "    tf_example = tf.train.Example(\n",
    "      features=tf.train.Features(\n",
    "        feature={\n",
    "          \"image/height\": dataset_util.int64_feature(height),\n",
    "          \"image/width\": dataset_util.int64_feature(width),\n",
    "          \"image/filename\": dataset_util.bytes_feature(file_name),\n",
    "          \"image/source_id\": dataset_util.bytes_feature(file_name),\n",
    "          \"image/encoded\": dataset_util.bytes_feature(encoded_jpg),\n",
    "          \"image/format\": dataset_util.bytes_feature(image_format),\n",
    "          \"image/object/bbox/xmin\": dataset_util.float_list_feature(xmins),\n",
    "          \"image/object/bbox/xmax\": dataset_util.float_list_feature(xmaxs),\n",
    "          \"image/object/bbox/ymin\": dataset_util.float_list_feature(ymins),\n",
    "          \"image/object/bbox/ymax\": dataset_util.float_list_feature(ymaxs),\n",
    "          \"image/object/class/text\": dataset_util.bytes_list_feature(classes_text),\n",
    "          \"image/object/class/label\": dataset_util.int64_list_feature(classes),\n",
    "        }\n",
    "      )\n",
    "    )\n",
    "    writer_id = random.choices([0, 1], weights=[0.9, 0.1])[0]\n",
    "    writers[writer_id].write(tf_example.SerializeToString())\n",
    "\n",
    "for writer in writers:\n",
    "  writer.close()\n",
    "\n",
    "test_record_fname = '/content/training_data/annotations/test.record'\n",
    "train_record_fname = '/content/training_data/annotations/train.record'\n",
    "label_map_pbtxt_fname = '/content/training_data/label_map.pbtxt'\n",
    "num_steps = 5000\n",
    "num_eval_steps = 50\n",
    "batch_size = 24\n",
    "MODEL = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
    "pipeline_file = 'ssd_mobilenet_v2_coco.config'\n",
    "\n",
    "%cd /content/models/research\n",
    "\n",
    "MODEL_FILE = Path(MODEL + '.tar.gz')\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "DEST_DIR = Path('/content/models/research/pretrained_model')\n",
    "\n",
    "if not MODEL_FILE.exists():\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE.name, MODEL_FILE.name)\n",
    "\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "MODEL_FILE.unlink()\n",
    "if DEST_DIR.exists():\n",
    "  rmtree(DEST_DIR)\n",
    "Path(MODEL).replace(DEST_DIR)\n",
    "\n",
    "fine_tune_checkpoint = DEST_DIR / \"model.ckpt\"\n",
    "\n",
    "pipeline_fname = Path(\"/content/models/research/object_detection/samples/configs/\") / pipeline_file\n",
    "iou_threshold = 0.5\n",
    "num_classes = len(category_index)\n",
    "with pipeline_fname.open() as f:\n",
    "  s = f.read()\n",
    "with pipeline_fname.open(mode=\"w\") as f:\n",
    "  # fine_tune_checkpoint\n",
    "  s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "              'fine_tune_checkpoint: \"{}\"'.format(str(fine_tune_checkpoint)), s)\n",
    "\n",
    "  # tfrecord files train and test.\n",
    "  s = re.sub(\n",
    "      '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "  s = re.sub(\n",
    "      '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    "\n",
    "  # label_map_path\n",
    "  s = re.sub(\n",
    "      'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "  # Set training batch_size.\n",
    "  s = re.sub('batch_size: [0-9]+',\n",
    "              'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "  # Set training steps, num_steps\n",
    "  s = re.sub('num_steps: [0-9]+',\n",
    "              'num_steps: {}'.format(num_steps), s)\n",
    "\n",
    "  # Set number of classes num_classes.\n",
    "  s = re.sub('num_classes: [0-9]+',\n",
    "              'num_classes: {}'.format(num_classes), s)\n",
    "  # Set number of classes num_classes.\n",
    "  s = re.sub('iou_threshold: [0-9].[0-9]+',\n",
    "              'iou_threshold: {}'.format(iou_threshold), s)\n",
    "\n",
    "  f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJv7DexF_q6W"
   },
   "source": [
    "# 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIv_0IUL0QPd"
   },
   "outputs": [],
   "source": [
    "model_dir = 'training/'\n",
    "!python /content/models/research/object_detection/model_main.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MixEodVk_9iL"
   },
   "source": [
    "# 5. Generate and download the files needed for the OAK-D device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9g6xLdolBBg2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from google.colab import files\n",
    "\n",
    "output_directory = './fine_tuned_model'\n",
    "\n",
    "lst = os.listdir(model_dir)\n",
    "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
    "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
    "last_model = lst[steps.argmax()].replace('.meta', '')\n",
    "\n",
    "last_model_path = os.path.join(model_dir, last_model)\n",
    "\n",
    "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --output_directory={output_directory} \\\n",
    "    --trained_checkpoint_prefix={last_model_path}\n",
    "\n",
    "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lGCjfLuTkBed"
   },
   "outputs": [],
   "source": [
    "%cd /content/TRT-SSD-MobileNetV2\n",
    "import uff\n",
    "import tensorrt as trt\n",
    "import graphsurgeon as gs\n",
    "import config as model\n",
    "from google.colab import files\n",
    "\n",
    "# initialize\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "trt.init_libnvinfer_plugins(TRT_LOGGER, '')\n",
    "runtime = trt.Runtime(TRT_LOGGER)\n",
    "\n",
    "\n",
    "# compile model into TensorRT\n",
    "if not os.path.isfile(OUTPUT_MODEL + '.bin'):\n",
    "    dynamic_graph = model.add_plugin(gs.DynamicGraph(pb_fname))\n",
    "    uff_model = uff.from_tensorflow(dynamic_graph.as_graph_def(), model.output_name, output_filename='tmp.uff')\n",
    "\n",
    "    with trt.Builder(TRT_LOGGER) as builder, builder.create_network() as network, trt.UffParser() as parser:\n",
    "        builder.max_workspace_size = 1 << 28\n",
    "        builder.max_batch_size = 1\n",
    "        builder.fp16_mode = True\n",
    "\n",
    "        parser.register_input('Input', model.dims)\n",
    "        parser.register_output('MarkOutput_0')\n",
    "        parser.parse('tmp.uff', network)\n",
    "        engine = builder.build_cuda_engine(network)\n",
    "\n",
    "        buf = engine.serialize()\n",
    "        with open(OUTPUT_MODEL + '.bin') as f:\n",
    "            f.write(buf)\n",
    "\n",
    "files.download(OUTPUT_MODEL + '.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xoHBhlJ42TY"
   },
   "source": [
    "# 6. Test the custom model\n",
    "\n",
    "Afterwards you can load the binary file with tensorrt on jetson devices and integrate it to your pipelines.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SuperAnnotate/Jestson: MobileNetSSD Deployment.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
