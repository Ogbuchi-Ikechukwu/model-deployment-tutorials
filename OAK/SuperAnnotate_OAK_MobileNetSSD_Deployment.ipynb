{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\"><td><a target=\"_blank\" href=\"https://colab.research.google.com/github/superannotateai/model-deployment-tutorials/blob/main/OAK/SuperAnnotate_OAK_MobileNetSSD_Deployment.ipynb\"><img src=\"https://user-images.githubusercontent.com/25985824/104791629-6e618700-5769-11eb-857f-d176b37d2496.png\" height=\"32\" width=\"32\"> Try in Google Colab</a></td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P14SDT47-Kcf"
   },
   "source": [
    "# 1. Install Prerequisites \n",
    "(Please click on **RESTART RUNTIME** button when it appears in the output of this code block)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IeakIbyX0vJu"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "\n",
    "!sudo apt-get install -y pciutils cpio\n",
    "!sudo apt autoremove\n",
    "!wget http://registrationcenter-download.intel.com/akdlm/irc_nas/16345/l_openvino_toolkit_p_2020.1.023.tgz\n",
    "path = \"l_openvino_toolkit_p_2020.1.023.tgz\"\n",
    "!tar xf \"{path}\"\n",
    "\n",
    "%cd l_openvino_toolkit_p_2020.1.023/\n",
    "!./install_openvino_dependencies.sh && \\\n",
    "    sed -i 's/decline/accept/g' silent.cfg && \\\n",
    "    ./install.sh --silent silent.cfg\n",
    "\n",
    "!bash /content/l_openvino_toolkit_p_2020.1.023/install_openvino_dependencies.sh\n",
    "!bash /opt/intel/openvino/deployment_tools/model_optimizer/install_prerequisites/install_prerequisites.sh\n",
    "\n",
    "!pip install superannotate\n",
    "!pip install google-resumable-media==0.5.0\n",
    "\n",
    "!pip install numpy==1.17.5\n",
    "!pip install tf_slim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxLgFeFi-hqZ"
   },
   "source": [
    "# 2. Setup your SuperAnnotate token, project names of trianing images and desired output model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eM8xn82K-uUm"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "\n",
    "TOKEN = \"For Pro Users, the Token-ID can be generated in the teams section\"\n",
    "PROJECT_NAMES = [\"Mask - batch 1\", \"Mask - batch 2\"]\n",
    "OUTPUT_MODEL = \"sa-tutorial\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mU4uDCW-Wp7"
   },
   "source": [
    "# 3. Download and preprocess the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FITOUc3E9JXU"
   },
   "outputs": [],
   "source": [
    "import superannotate as sa\n",
    "import json\n",
    "import os \n",
    "from shutil import copy, make_archive, rmtree\n",
    "import re\n",
    "import glob\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "\n",
    "\n",
    "proj_folder = dict(zip(PROJECT_NAMES, [\"proj_\" + str(i) for i in range(len(PROJECT_NAMES))]))\n",
    "token_json = {\"token\": TOKEN}\n",
    "with open('sa_config.json', 'w') as f:\n",
    "  json.dump(token_json, f)\n",
    "\n",
    "sa.init('sa_config.json')\n",
    "\n",
    "for project_name, folder_name in proj_folder.items():\n",
    "  if not os.path.exists('./training_data/' + folder_name):\n",
    "    os.makedirs('training_data/' + folder_name)\n",
    "  completed_images = sa.search_images(project_name, annotation_status=\"Completed\")\n",
    "  for completed_image in completed_images:\n",
    "    sa.download_image(project_name, completed_image, local_dir_path='./training_data/' + folder_name)\n",
    "  export = sa.prepare_export(project_name, annotation_statuses=[\"Completed\"])\n",
    "  sa.download_export(project_name, export, './training_data/' + folder_name)\n",
    "\n",
    "%cd /content\n",
    "!git clone --quiet https://github.com/tensorflow/models.git\n",
    "%cd /content/models/\n",
    "!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n",
    "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
    "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
    "!pip install -q pycocotools\n",
    "%cd /content/models/research\n",
    "!protoc object_detection/protos/*.proto --python_out=.\n",
    "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
    "\n",
    "%cd /content/models/research/\n",
    "from object_detection.utils import dataset_util, label_map_util\n",
    "data_base = Path(\"/content/training_data\")\n",
    "class_names = set()\n",
    "column_names = [\"filename\", \"width\", \"height\", \"class\", \"xmin\", \"ymin\", \"xmax\", \"ymax\"]\n",
    "for project_dir in data_base.glob(\"*\"):\n",
    "  with open(project_dir / \"classes\" / \"classes.json\") as f:\n",
    "    proj_class_data = json.load(f)\n",
    "  for class_entry in proj_class_data:\n",
    "    class_names.add(class_entry[\"name\"])\n",
    "class_names = sorted(list(class_names))\n",
    "pbtxt_content = \"\"\n",
    "for i, class_name in enumerate(class_names):\n",
    "  pbtxt_content = (pbtxt_content + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name))\n",
    "pbtxt_content = pbtxt_content.strip()\n",
    "with (data_base / \"label_map.pbtxt\").open(mode=\"w\") as f:\n",
    "  f.write(pbtxt_content)\n",
    "\n",
    "tf_record_dir = data_base / \"annotations\"\n",
    "if not tf_record_dir.exists():\n",
    "  tf_record_dir.mkdir()\n",
    "\n",
    "writers = [tf.python_io.TFRecordWriter(str(tf_record_dir / \"train.record\")), tf.python_io.TFRecordWriter(str(tf_record_dir / \"test.record\"))]\n",
    "label_map = label_map_util.load_labelmap(str(data_base / \"label_map.pbtxt\"))\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=90, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "label_map = {}\n",
    "for k, v in category_index.items():\n",
    "    label_map[v.get(\"name\")] = v.get(\"id\")\n",
    "    \n",
    "for project_dir in list(data_base.glob(\"*\")):\n",
    "  annot_paths = list(project_dir.glob(\"*___objects.json\"))\n",
    "  for annot_path in annot_paths:\n",
    "    with open(annot_path) as f:\n",
    "      annot_data = json.load(f)\n",
    "    file_name = annot_path.name[:-15]\n",
    "    with tf.gfile.GFile(str(project_dir / file_name), \"rb\") as fid:\n",
    "      encoded_jpg = fid.read()\n",
    "    width = annot_data[\"metadata\"][\"width\"]\n",
    "    height = annot_data[\"metadata\"][\"height\"]\n",
    "    image_format = Path(file_name).suffix[1:].encode(\"utf8\")\n",
    "    file_name = file_name.encode(\"utf8\")\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "    for inst_data in annot_data[\"instances\"]:\n",
    "      points = inst_data[\"points\"]\n",
    "      xmin, xmax = min(points[\"x1\"], points[\"x2\"]), max(points[\"x1\"], points[\"x2\"])\n",
    "      ymin, ymax = min(points[\"y1\"], points[\"y2\"]), max(points[\"y1\"], points[\"y2\"])\n",
    "      xmins.append(xmin / width)\n",
    "      xmaxs.append(xmax / width)\n",
    "      ymins.append(ymin / height)\n",
    "      ymaxs.append(ymax / height)\n",
    "      classes_text.append(inst_data[\"className\"].encode(\"utf8\"))\n",
    "      class_index = label_map.get(inst_data[\"className\"])\n",
    "      classes.append(class_index)\n",
    "    tf_example = tf.train.Example(\n",
    "      features=tf.train.Features(\n",
    "        feature={\n",
    "          \"image/height\": dataset_util.int64_feature(height),\n",
    "          \"image/width\": dataset_util.int64_feature(width),\n",
    "          \"image/filename\": dataset_util.bytes_feature(file_name),\n",
    "          \"image/source_id\": dataset_util.bytes_feature(file_name),\n",
    "          \"image/encoded\": dataset_util.bytes_feature(encoded_jpg),\n",
    "          \"image/format\": dataset_util.bytes_feature(image_format),\n",
    "          \"image/object/bbox/xmin\": dataset_util.float_list_feature(xmins),\n",
    "          \"image/object/bbox/xmax\": dataset_util.float_list_feature(xmaxs),\n",
    "          \"image/object/bbox/ymin\": dataset_util.float_list_feature(ymins),\n",
    "          \"image/object/bbox/ymax\": dataset_util.float_list_feature(ymaxs),\n",
    "          \"image/object/class/text\": dataset_util.bytes_list_feature(classes_text),\n",
    "          \"image/object/class/label\": dataset_util.int64_list_feature(classes),\n",
    "        }\n",
    "      )\n",
    "    )\n",
    "    writer_id = random.choices([0, 1], weights=[0.9, 0.1])[0]\n",
    "    writers[writer_id].write(tf_example.SerializeToString())\n",
    "\n",
    "for writer in writers:\n",
    "  writer.close()\n",
    "\n",
    "test_record_fname = '/content/training_data/annotations/test.record'\n",
    "train_record_fname = '/content/training_data/annotations/train.record'\n",
    "label_map_pbtxt_fname = '/content/training_data/label_map.pbtxt'\n",
    "num_steps = 5000\n",
    "num_eval_steps = 50\n",
    "batch_size = 24\n",
    "MODEL = 'ssd_mobilenet_v2_coco_2018_03_29'\n",
    "pipeline_file = 'ssd_mobilenet_v2_coco.config'\n",
    "\n",
    "%cd /content/models/research\n",
    "\n",
    "MODEL_FILE = Path(MODEL + '.tar.gz')\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "DEST_DIR = Path('/content/models/research/pretrained_model')\n",
    "\n",
    "if not MODEL_FILE.exists():\n",
    "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE.name, MODEL_FILE.name)\n",
    "\n",
    "tar = tarfile.open(MODEL_FILE)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "MODEL_FILE.unlink()\n",
    "if DEST_DIR.exists():\n",
    "  rmtree(DEST_DIR)\n",
    "Path(MODEL).replace(DEST_DIR)\n",
    "\n",
    "fine_tune_checkpoint = DEST_DIR / \"model.ckpt\"\n",
    "\n",
    "pipeline_fname = Path(\"/content/models/research/object_detection/samples/configs/\") / pipeline_file\n",
    "iou_threshold = 0.5\n",
    "num_classes = len(category_index)\n",
    "with pipeline_fname.open() as f:\n",
    "  s = f.read()\n",
    "with pipeline_fname.open(mode=\"w\") as f:\n",
    "  # fine_tune_checkpoint\n",
    "  s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "              'fine_tune_checkpoint: \"{}\"'.format(str(fine_tune_checkpoint)), s)\n",
    "\n",
    "  # tfrecord files train and test.\n",
    "  s = re.sub(\n",
    "      '(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "  s = re.sub(\n",
    "      '(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n",
    "\n",
    "  # label_map_path\n",
    "  s = re.sub(\n",
    "      'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "  # Set training batch_size.\n",
    "  s = re.sub('batch_size: [0-9]+',\n",
    "              'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "  # Set training steps, num_steps\n",
    "  s = re.sub('num_steps: [0-9]+',\n",
    "              'num_steps: {}'.format(num_steps), s)\n",
    "\n",
    "  # Set number of classes num_classes.\n",
    "  s = re.sub('num_classes: [0-9]+',\n",
    "              'num_classes: {}'.format(num_classes), s)\n",
    "  # Set number of classes num_classes.\n",
    "  s = re.sub('iou_threshold: [0-9].[0-9]+',\n",
    "              'iou_threshold: {}'.format(iou_threshold), s)\n",
    "\n",
    "  f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJv7DexF_q6W"
   },
   "source": [
    "# 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIv_0IUL0QPd"
   },
   "outputs": [],
   "source": [
    "model_dir = 'training/'\n",
    "!python /content/models/research/object_detection/model_main.py \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --num_eval_steps={num_eval_steps}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MixEodVk_9iL"
   },
   "source": [
    "# 5. Generate and download the files needed for the OAK-D device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9g6xLdolBBg2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from google.colab import files\n",
    "\n",
    "output_directory = './fine_tuned_model'\n",
    "\n",
    "lst = os.listdir(model_dir)\n",
    "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
    "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
    "last_model = lst[steps.argmax()].replace('.meta', '')\n",
    "\n",
    "last_model_path = os.path.join(model_dir, last_model)\n",
    "\n",
    "!python /content/models/research/object_detection/export_inference_graph.py \\\n",
    "    --input_type=image_tensor \\\n",
    "    --pipeline_config_path={pipeline_fname} \\\n",
    "    --output_directory={output_directory} \\\n",
    "    --trained_checkpoint_prefix={last_model_path}\n",
    "\n",
    "pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n",
    "\n",
    "%cd /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/\n",
    "\n",
    "with open('ssd_v2_support.json', 'r') as file :\n",
    "  filedata = file.read()\n",
    "\n",
    "filedata = filedata.replace('\"Postprocessor/ToFloat\"', '\"Postprocessor/Cast_1\"')\n",
    "\n",
    "with open('ssd_v2_support.json', 'w') as file:\n",
    "  file.write(filedata)\n",
    "\n",
    "%cd \"/content/models/research/fine_tuned_model/\"\n",
    "!source /opt/intel/openvino/bin/setupvars.sh && \\\n",
    "    python /opt/intel/openvino/deployment_tools/model_optimizer/mo.py \\\n",
    "    --input_model frozen_inference_graph.pb \\\n",
    "    --tensorflow_use_custom_operations_config /opt/intel/openvino/deployment_tools/model_optimizer/extensions/front/tf/ssd_v2_support.json \\\n",
    "    --tensorflow_object_detection_api_pipeline_config pipeline.config \\\n",
    "    --reverse_input_channels \\\n",
    "    --output_dir /content/ \\\n",
    "    --data_type FP16\n",
    "\n",
    "%cd /content/\n",
    "blob_dir = Path(\"/content/\" + OUTPUT_MODEL)\n",
    "if not blob_dir.exists():\n",
    "  blob_dir.mkdir()\n",
    "\n",
    "binfile = \"/content/frozen_inference_graph.bin\"\n",
    "xmlfile = \"/content/frozen_inference_graph.xml\"\n",
    "url = \"http://69.164.214.171:8080\"\n",
    "\n",
    "payload = {'compiler_params': '-ip U8 -VPU_MYRIAD_PLATFORM VPU_MYRIAD_2480 -VPU_NUMBER_OF_SHAVES 4 -VPU_NUMBER_OF_CMX_SLICES 4'}\n",
    "upload_files = [\n",
    "  ('definition', open(xmlfile,'rb')),\n",
    "  ('weights', open(binfile,'rb'))\n",
    "]\n",
    "\n",
    "response = requests.request(\"POST\", url, data = payload, files = upload_files)\n",
    "blobname = OUTPUT_MODEL + '.blob.sh14cmx14NCE1'\n",
    "with open(blob_dir / blobname, 'wb') as f:\n",
    "  f.write(response.content)\n",
    "\n",
    "%cd /content/\n",
    "!wget https://raw.githubusercontent.com/luxonis/depthai/main/resources/nn/mobilenet-ssd/model.yml\n",
    "!wget https://raw.githubusercontent.com/luxonis/depthai/main/resources/nn/mobilenet-ssd/mobilenet-ssd.json\n",
    "\n",
    "with open('/content/model.yml', 'r') as f:\n",
    "    s = f.read()\n",
    "with open('/content/' + OUTPUT_MODEL + '/model.yml', 'w') as f:\n",
    "    f.write(s)\n",
    "\n",
    "with open('mobilenet-ssd.json', 'r') as f:\n",
    "  settings_json = json.load(f)\n",
    "settings_json[\"mappings\"][\"labels\"] = class_names\n",
    "with open('/content/' + OUTPUT_MODEL + '/' + OUTPUT_MODEL + '.json', 'w') as f:\n",
    "  json.dump(settings_json, f)\n",
    "make_archive(OUTPUT_MODEL, 'zip', OUTPUT_MODEL)\n",
    "files.download(OUTPUT_MODEL + '.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iscmAv4AQCZ"
   },
   "source": [
    "# 6. Copy and paste the generated model in 'depthai' directory\n",
    "\n",
    "Please follow these steps on your local machine to get the model running\n",
    "\n",
    "**On Windows** \n",
    "\n",
    "Cut the downloaded \\$OUTPUT_MODEL.zip file from your Downloads folder and paste it in \\$DEPTHAI_ROOT_DIR/resources/nn/ folder. Then right click on it and choose \"Extract Here\" option. You can delete the zip file afterwards.\n",
    "\n",
    "**On Mac**\n",
    "\n",
    "Cut the downloaded \\$OUTPUT_MODEL.zip file from your Downloads folder and paste it in \\$DEPTHAI_ROOT_DIR/resources/nn/ folder. Then double click on it. You can delete the zip file afterwards.\n",
    "\n",
    "**On Linux**\n",
    "\n",
    "You can either do it with GUI following the steps discussed in **On Windows** section or run the following commands in terminal\n",
    "\n",
    "```\n",
    "mv ~/Downloads/$OUTPUT_MODEL.zip $DEPTHAI_ROOT_DIR/resources/nn/\n",
    "cd $DEPTHAI_ROOT_DIR/resources/nn/\n",
    "unzip $OUTPUT_MODEL.zip \n",
    "rm $OUTPUT_MODEL.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xoHBhlJ42TY"
   },
   "source": [
    "# 7. Test the custom model\n",
    "\n",
    "Afterwards you can run the new model with the following command from the $DEPTHAI_ROOT_DIR directory:\n",
    "\n",
    "```\n",
    "python3 depthai_demo.py -dd -cnn $OUTPUT_MODEL\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SuperAnnotate/OAK: MobileNetSSD Deployment.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
