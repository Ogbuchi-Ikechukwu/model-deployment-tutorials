{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\"><td><a target=\"_blank\" href=\"https://colab.research.google.com/github/superannotateai/model-deployment-tutorials/blob/main/OAK/SuperAnnotate_OAK_YOLOv4_tiny_Deployment.ipynb\"><img src=\"https://user-images.githubusercontent.com/25985824/104791629-6e618700-5769-11eb-857f-d176b37d2496.png\" height=\"32\" width=\"32\"> Try in Google Colab</a></td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P14SDT47-Kcf"
   },
   "source": [
    "# 1. Install Prerequisites \n",
    "(Please click on **RESTART RUNTIME** button when it appears in the output of this code block)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IeakIbyX0vJu",
    "outputId": "ccac47ac-f088-4829-a36f-edd933fe458b"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/AlexeyAB/darknet.git\n",
    "!git clone https://github.com/GotG/yolotinyv3_medmask_demo\n",
    "!git clone https://github.com/TNTWEN/OpenVINO-YOLOV4.git\n",
    "\n",
    "%cd darknet\n",
    "import re\n",
    "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
    "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
    "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
    "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
    "!make\n",
    "!chmod +x ./darknet\n",
    "%cd ../\n",
    "\n",
    "!sudo apt-get install -y pciutils cpio\n",
    "!sudo apt autoremove\n",
    "!wget http://registrationcenter-download.intel.com/akdlm/irc_nas/16803/l_openvino_toolkit_p_2020.4.287.tgz\n",
    "path = \"l_openvino_toolkit_p_2020.4.287.tgz\"\n",
    "!tar xf \"{path}\"\n",
    "\n",
    "%cd l_openvino_toolkit_p_2020.4.287/\n",
    "!./install_openvino_dependencies.sh && \\\n",
    "    sed -i 's/decline/accept/g' silent.cfg && \\\n",
    "    ./install.sh --silent silent.cfg\n",
    "\n",
    "!bash /content/l_openvino_toolkit_p_2020.4.287/install_openvino_dependencies.sh\n",
    "!bash /opt/intel/openvino/deployment_tools/model_optimizer/install_prerequisites/install_prerequisites.sh\n",
    "\n",
    "!pip install superannotate\n",
    "!pip install google-resumable-media==0.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxLgFeFi-hqZ"
   },
   "source": [
    "# 2. Setup your SuperAnnotate token, project names of trianing images and desired output model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eM8xn82K-uUm"
   },
   "outputs": [],
   "source": [
    "TOKEN = \"For Pro Users, the Token-ID can be generated in the teams section\"\n",
    "PROJECT_NAMES = [\"Mask - batch 1\", \"Mask - batch 2\"]\n",
    "OUTPUT_MODEL = \"sa-tutorial\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3mU4uDCW-Wp7"
   },
   "source": [
    "# 3. Download and preprocess the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FITOUc3E9JXU",
    "outputId": "8ef23d6f-e624-4411-dc38-dae7a9b5bbce"
   },
   "outputs": [],
   "source": [
    "import superannotate as sa\n",
    "import json\n",
    "import os \n",
    "from shutil import copy, make_archive\n",
    "import re\n",
    "\n",
    "proj_folder = dict(zip(PROJECT_NAMES, [\"proj_\" + str(i) for i in range(len(PROJECT_NAMES))]))\n",
    "token_json = {\"token\": TOKEN}\n",
    "with open('sa_config.json', 'w') as f:\n",
    "  json.dump(token_json, f)\n",
    "\n",
    "sa.init('sa_config.json')\n",
    "\n",
    "for project_name, folder_name in proj_folder.items():\n",
    "  if not os.path.exists('./training_data/' + folder_name):\n",
    "    os.makedirs('training_data/' + folder_name)\n",
    "  completed_images = sa.search_images(project_name, annotation_status=\"Completed\")\n",
    "  for completed_image in completed_images:\n",
    "    sa.download_image(project_name, completed_image, local_dir_path='./training_data/' + folder_name)\n",
    "  export = sa.prepare_export(project_name, annotation_statuses=[\"Completed\"])\n",
    "  sa.download_export(project_name, export, './training_data/' + folder_name)\n",
    "\n",
    "class_names = set()\n",
    "for folder_name in proj_folder.values():\n",
    "  with open('/content/training_data/' + folder_name +'/classes/classes.json', 'r') as f:\n",
    "    proj_class_data = json.load(f)\n",
    "  for class_entry in proj_class_data:\n",
    "    class_names.add(class_entry[\"name\"])\n",
    "\n",
    "class_names = list(class_names)\n",
    "class_names_yolo_id = dict(zip(class_names, range(len(class_names))))\n",
    "\n",
    "if not os.path.exists('/content/training_data/yolo_train'):\n",
    "  os.mkdir('/content/training_data/yolo_train')\n",
    "\n",
    "for folder_name in proj_folder.values():\n",
    "  folder_base = '/content/training_data/' + folder_name\n",
    "  folder_content = os.listdir(folder_base)\n",
    "  for folder_item_path in folder_content:\n",
    "    if folder_item_path.endswith(\"classes\"):\n",
    "      continue\n",
    "    elif folder_item_path.endswith(\"json\"):\n",
    "      yolo_annot_file_path = '/content/training_data/yolo_train/' + folder_name + '_' + os.path.splitext(folder_item_path.split(\"___\")[0])[0] + '.txt'\n",
    "      with open(folder_base + '/' + folder_item_path, 'r') as f:\n",
    "        annot_data = json.load(f)\n",
    "      img_h, img_w = annot_data[\"metadata\"][\"height\"], annot_data[\"metadata\"][\"width\"]\n",
    "      box_data = []\n",
    "      for annot_inst in annot_data[\"instances\"]:\n",
    "        if annot_inst[\"type\"] != \"bbox\":\n",
    "          continue\n",
    "        points = annot_inst[\"points\"]\n",
    "        x1, x2, y1, y2 = points[\"x1\"], points[\"x2\"], points[\"y1\"], points[\"y2\"]\n",
    "        center_x = str(((x1 + x2) / 2) / img_w)\n",
    "        center_y = str(((y1 + y2) / 2) / img_h)\n",
    "        width = str((max(x1, x2) - min(x1, x2)) / img_w)\n",
    "        height = str((max(y1, y2) - min(y1, y2)) / img_h)\n",
    "        inst_class_id = str(class_names_yolo_id[annot_inst[\"className\"]])\n",
    "        box_data.append(inst_class_id + ' ' + center_x + ' ' + center_y + ' ' + width + ' ' + height + '\\n')\n",
    "      with open(yolo_annot_file_path, 'w') as f:\n",
    "        for box_inst in box_data:\n",
    "          f.write(box_inst)\n",
    "    else:\n",
    "      copy(folder_base + '/' + folder_item_path, '/content/training_data/yolo_train/' + folder_name + '_' + folder_item_path)\n",
    "\n",
    "labels_path = '/content/yolotinyv3_medmask_demo/obj.names'\n",
    "\n",
    "with open(labels_path, 'w') as f:\n",
    "  for class_name, yolo_id in class_names_yolo_id.items():\n",
    "    f.write(class_name + '\\n')\n",
    "\n",
    "objdata = '/content/yolotinyv3_medmask_demo/obj.data'\n",
    "with open(objdata) as f:\n",
    "    s = f.read()\n",
    "\n",
    "num_classes = len(class_names_yolo_id.keys())\n",
    "s = re.sub('classes= \\d*','classes = ' + str(num_classes),s)\n",
    "\n",
    "with open(objdata, 'w') as f:\n",
    "  f.write(s)\n",
    "\n",
    "%cd yolotinyv3_medmask_demo/\n",
    "!python3 folder2textYolo.py 0 /content/training_data/yolo_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJv7DexF_q6W"
   },
   "source": [
    "# 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "8rkKGxj9Aa1p",
    "outputId": "39578c3d-0c6d-4960-bfcf-41992d6534e4"
   },
   "outputs": [],
   "source": [
    "max_batch= num_classes * 20 #recommended 2000\n",
    "step1 = 0.8 * max_batch\n",
    "step2 = 0.9 * max_batch\n",
    "subdivisions = 4\n",
    "num_filters = (num_classes + 5) * 3\n",
    "\n",
    "cfg_file = '/content/yolotinyv3_medmask_demo/yolov4-tiny.cfg'\n",
    "\n",
    "with open(cfg_file) as f:\n",
    "    s = f.read()\n",
    "\n",
    "s = re.sub('subdivisions=\\d*','subdivisions='+str(subdivisions),s)\n",
    "s = re.sub('max_batches = \\d*','max_batches = '+str(max_batch),s)\n",
    "s = re.sub('steps=\\d*,\\d*','steps='+\"{:.0f}\".format(step1)+','+\"{:.0f}\".format(step2),s)\n",
    "s = re.sub('classes=\\d*','classes='+str(num_classes),s)\n",
    "s = re.sub('pad=1\\nfilters=\\d*','pad=1\\nfilters='+\"{:.0f}\".format(num_filters),s)\n",
    "\n",
    "with open(cfg_file, 'w') as f:\n",
    "  f.write(s)\n",
    "\n",
    "%cd ../darknet/\n",
    "\n",
    "!./darknet detector train /content/yolotinyv3_medmask_demo/obj.data /content/yolotinyv3_medmask_demo/yolov4-tiny.cfg /content/yolotinyv3_medmask_demo/yolov4-tiny.conv.29 -dont_show -ext_output -map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MixEodVk_9iL"
   },
   "source": [
    "# 5. Generate and download the files needed for the OAK-D device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9g6xLdolBBg2",
    "outputId": "3134e754-d3d3-450b-d711-e1fc15cd3e03"
   },
   "outputs": [],
   "source": [
    "%tensorflow_version 1.x\n",
    "from google.colab import files\n",
    "import requests\n",
    "\n",
    "files.download('/content/darknet/backup/yolov4-tiny_best.weights')\n",
    "\n",
    "%cd /content/OpenVINO-YOLOV4/\n",
    "!python3 convert_weights_pb.py --class_names /content/yolotinyv3_medmask_demo/obj.names --data_format NHWC --weights_file /content/darknet/backup/yolov4-tiny_best.weights --tiny\n",
    "\n",
    "tiny_yolo_json = '/content/OpenVINO-YOLOV4/yolo_v4_tiny.json'\n",
    "with open(tiny_yolo_json) as f:\n",
    "    s = f.read()\n",
    "s = re.sub('\"classes\": \\d*','\"classes\": ' + str(num_classes),s)\n",
    "with open(tiny_yolo_json, 'w') as f:\n",
    "  f.write(s)\n",
    "\n",
    "!source /opt/intel/openvino/bin/setupvars.sh && \\\n",
    "    python /opt/intel/openvino/deployment_tools/model_optimizer/mo.py \\\n",
    "--input_model /content/OpenVINO-YOLOV4/frozen_darknet_yolov4_model.pb \\\n",
    "--transformations_config /content/OpenVINO-YOLOV4/yolo_v4_tiny.json  \\\n",
    "--batch 1 \\\n",
    "--data_type FP16 \\\n",
    "--reverse_input_channel \\\n",
    "--output_dir /content/yolotinyv3_medmask_demo/TinyIR\n",
    "\n",
    "os.mkdir(\"/content/\" + OUTPUT_MODEL)\n",
    "blob_dir = \"/content/\" + OUTPUT_MODEL\n",
    "\n",
    "binfile = \"/content/yolotinyv3_medmask_demo/TinyIR/frozen_darknet_yolov4_model.bin\"\n",
    "xmlfile = \"/content/yolotinyv3_medmask_demo/TinyIR/frozen_darknet_yolov4_model.xml\"\n",
    "\n",
    "url = \"http://69.164.214.171:8083/compile\"\n",
    "params = {\n",
    "    'version': '2020.1'\n",
    "}\n",
    "payload = {\n",
    "    'compile_type': 'myriad', \n",
    "    'compiler_params': '-ip U8 -VPU_MYRIAD_PLATFORM VPU_MYRIAD_2480 -VPU_NUMBER_OF_SHAVES 14 -VPU_NUMBER_OF_CMX_SLICES 14'\n",
    "}\n",
    "\n",
    "model_files = {\n",
    "    'definition': open(xmlfile, 'rb'),\n",
    "    'weights': open(binfile, 'rb')\n",
    "}\n",
    "response = requests.post(url, data=payload, files=model_files, params=params)\n",
    "blobname = OUTPUT_MODEL + '.blob.sh14cmx14NCE1'\n",
    "with open(blob_dir + '/' + blobname, 'wb') as f:\n",
    "  f.write(response.content)\n",
    "\n",
    "%cd /content/\n",
    "!wget https://raw.githubusercontent.com/luxonis/depthai/main/resources/nn/tiny-yolo-v3/model.yml\n",
    "!wget https://raw.githubusercontent.com/luxonis/depthai/main/resources/nn/tiny-yolo-v3/tiny-yolo-v3.json\n",
    "\n",
    "with open('/content/model.yml', 'r') as f:\n",
    "    s = f.read()\n",
    "s = re.sub('v3','v4',s)\n",
    "with open('/content/' + OUTPUT_MODEL + '/model.yml', 'w') as f:\n",
    "    f.write(s)\n",
    "with open('tiny-yolo-v3.json', 'r') as f:\n",
    "  settings_json = json.load(f)\n",
    "settings_json[\"NN_config\"][\"NN_specific_metadata\"][\"classes\"] = num_classes\n",
    "settings_json[\"mappings\"][\"labels\"] = list(class_names_yolo_id.keys())\n",
    "with open('/content/' + OUTPUT_MODEL + '/' + OUTPUT_MODEL + '.json', 'w') as f:\n",
    "  json.dump(settings_json, f)\n",
    "make_archive(OUTPUT_MODEL, 'zip', OUTPUT_MODEL)\n",
    "files.download(OUTPUT_MODEL + '.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_iscmAv4AQCZ"
   },
   "source": [
    "# 6. Copy and paste the generated model in 'depthai' directory\n",
    "\n",
    "Please follow these steps on your local machine to get the model running\n",
    "\n",
    "**On Windows** \n",
    "\n",
    "Cut the downloaded \\$OUTPUT_MODEL.zip file from your Downloads folder and paste it in \\$DEPTHAI_ROOT_DIR/resources/nn/ folder. Then right click on it and choose \"Extract Here\" option. You can delete the zip file afterwards.\n",
    "\n",
    "**On Mac**\n",
    "\n",
    "Cut the downloaded \\$OUTPUT_MODEL.zip file from your Downloads folder and paste it in \\$DEPTHAI_ROOT_DIR/resources/nn/ folder. Then double click on it. You can delete the zip file afterwards.\n",
    "\n",
    "**On Linux**\n",
    "\n",
    "You can either do it with GUI following the steps discussed in **On Windows** section or run the following commands in terminal\n",
    "\n",
    "```\n",
    "mv ~/Downloads/$OUTPUT_MODEL.zip $DEPTHAI_ROOT_DIR/resources/nn/\n",
    "cd $DEPTHAI_ROOT_DIR/resources/nn/\n",
    "unzip $OUTPUT_MODEL.zip \n",
    "rm $OUTPUT_MODEL.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_xoHBhlJ42TY"
   },
   "source": [
    "# 7. Test the custom model\n",
    "\n",
    "Afterwards you can run the new model with the following command from the $DEPTHAI_ROOT_DIR directory:\n",
    "\n",
    "```\n",
    "python3 depthai_demo.py -dd -cnn $OUTPUT_MODEL\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0SuV_uN4vDV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SuperAnnotate/OAK: YOLOv4-tiny Deployment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
